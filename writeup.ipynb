{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de59065",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c0fdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ml3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pytorch3d as p3d\n",
    "import torch\n",
    "from starter.utils import get_mesh_renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2825ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = get_mesh_renderer(image_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e9ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = torch.tensor([[[0.0, 0.0, 0.0],\n",
    "                          [1.0, 0.0, 0.0],\n",
    "                          [0.0, 1.0, 0.0]]])  # 1 x N_v x 3 tensor.\n",
    "faces = torch.tensor([[[0, 1, 2]]])  # 1 x N_f x 3 tensor.\n",
    "textures =  torch.tensor([[[1.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0],\n",
    "                             [0.0, 0.0, 1.0]]])  # 1 x N_v x 3 tensor.\n",
    "meshes = p3d.structures.Meshes(\n",
    "    verts=vertices,\n",
    "    faces=faces,\n",
    "    textures=p3d.renderer.TexturesVertex(textures),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e3b443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = p3d.renderer.FoVPerspectiveCameras(\n",
    "    R=torch.eye(3).unsqueeze(0),\n",
    "    T=torch.tensor([[0.0, 0.0, 3.0]]),\n",
    "    fov=60.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b573a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lights = p3d.renderer.PointLights(location=[[0.0, 0.0, -3.0]])\n",
    "rend = renderer(meshes, cameras=cameras, lights=lights)\n",
    "image = rend[0, ..., :3].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a655aad0",
   "metadata": {},
   "source": [
    "# 1. Practicing with Cameras (15 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42213a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from starter.utils import get_mesh_renderer\n",
    "\n",
    "def camera360(mesh, img_size=256, num_frames=36, duration=1000, distance=3.0, elevation=15.0, output_path=None):\n",
    "    renderer = get_mesh_renderer(img_size)\n",
    "\n",
    "    duration //= num_frames  # duration per frame in milliseconds\n",
    "    degrees = np.linspace(0, 360, num=num_frames).tolist()\n",
    "    my_images = []\n",
    "\n",
    "    # lights = p3d.renderer.PointLights(location=[[0.0, 0.0, -3.0]])\n",
    "\n",
    "    for angle in tqdm(degrees):\n",
    "        R, T = p3d.renderer.cameras.look_at_view_transform(distance, elevation, angle)\n",
    "        cameras = p3d.renderer.FoVPerspectiveCameras(R=R, T=T, fov=60.0)\n",
    "        lights = p3d.renderer.PointLights(location=cameras.get_camera_center())\n",
    "        rend = renderer(mesh, cameras=cameras, lights=lights)\n",
    "        image = rend[0, ..., :3].numpy()\n",
    "        my_images.append((image * 255).astype(np.uint8))\n",
    "\n",
    "    if output_path is not None:\n",
    "        imageio.mimsave(output_path, my_images, duration=duration, loop=0)\n",
    "        return None\n",
    "    else:\n",
    "        return my_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc858154",
   "metadata": {},
   "source": [
    "## 1.1. 360-degree Renders (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95fce807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:28<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "import pytorch3d as p3d\n",
    "\n",
    "cow_mesh = p3d.io.load_objs_as_meshes([\"data/cow.obj\"])\n",
    "camera360(cow_mesh, output_path=\"output/cow-360.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d05fa",
   "metadata": {},
   "source": [
    "Result:\n",
    "\n",
    "![360-degree renders of the cow](output/cow-360.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe5bae",
   "metadata": {},
   "source": [
    "## 1.2 Re-creating the Dolly Zoom (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m starter.dolly_zoom --duration 30 --num_frames 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8971ba",
   "metadata": {},
   "source": [
    "Result:\n",
    "\n",
    "![Dolly Zoom Effect](output/dolly.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef679a2",
   "metadata": {},
   "source": [
    "# 2. Practicing with Meshes (10 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0498730",
   "metadata": {},
   "source": [
    "## 2.1 Constructing a Tetrahedron (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f8055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 71.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import pytorch3d as p3d\n",
    "import torch\n",
    "\n",
    "points = torch.tensor([[\n",
    "    [0.0, 0.0, -1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [1.0, 1.0, 1.0],\n",
    "    [1.0, -1.0, 1.0],\n",
    "]])\n",
    "faces = torch.tensor([[\n",
    "    [0, 1, 2],\n",
    "    [0, 1, 3],\n",
    "    [1, 2, 3],\n",
    "    [0, 2, 3],\n",
    "]])\n",
    "textures = torch.tensor([[\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 1.0],\n",
    "]])\n",
    "textures = textures[:, :, None, None, :]\n",
    "\n",
    "tetrahedron = p3d.structures.Meshes(\n",
    "    verts=points,\n",
    "    faces=faces,\n",
    "    textures=p3d.renderer.TexturesAtlas(textures)\n",
    ")\n",
    "\n",
    "camera360(tetrahedron, num_frames=100, duration=2000, output_path=\"output/tetrahedron.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34529938",
   "metadata": {},
   "source": [
    "Result:\n",
    "\n",
    "- Number of vertices: 4\n",
    "- Number of faces: 4\n",
    "\n",
    "![](output/tetrahedron.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c16771",
   "metadata": {},
   "source": [
    "## 2.2 Constructing a Cube (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f3b6db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 65.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import pytorch3d as p3d\n",
    "import torch\n",
    "\n",
    "points = torch.tensor([[\n",
    "    [-1.0, -1.0, -1.0],\n",
    "    [-1.0, -1.0, 1.0],\n",
    "    [-1.0, 1.0, -1.0],\n",
    "    [-1.0, 1.0, 1.0],\n",
    "    [1.0, -1.0, -1.0],\n",
    "    [1.0, -1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0],\n",
    "    [1.0, 1.0, 1.0],\n",
    "]])\n",
    "faces = torch.tensor([[\n",
    "    [0, 4, 5],\n",
    "    [0, 5, 1],\n",
    "    [4, 6, 7],\n",
    "    [4, 7, 5],\n",
    "    [6, 2, 3],\n",
    "    [6, 3, 7],\n",
    "    [2, 0, 1],\n",
    "    [2, 1, 3],\n",
    "    [1, 5, 7],\n",
    "    [1, 7, 3],\n",
    "    [2, 6, 4],\n",
    "    [2, 4, 0],\n",
    "]])\n",
    "textures = torch.tensor([[\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 1.0],\n",
    "    [1.0, 1.0, 0.0],\n",
    "    [1.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 1.0],\n",
    "    [0.0, 1.0, 1.0],\n",
    "]])\n",
    "textures = textures[:, :, None, None, :]\n",
    "\n",
    "cube = p3d.structures.Meshes(\n",
    "    verts=points,\n",
    "    faces=faces,\n",
    "    textures=p3d.renderer.TexturesAtlas(textures)\n",
    ")\n",
    "\n",
    "camera360(cube, num_frames=100, duration=2000, distance=5, elevation=30, output_path=\"output/cube.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1025e9",
   "metadata": {},
   "source": [
    "Result:\n",
    "\n",
    "- Number of vertices: 8\n",
    "- Number of triangle faces: 12\n",
    "\n",
    "![](output/cube.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742d522",
   "metadata": {},
   "source": [
    "# 3. Re-texturing a mesh (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cde51404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:31<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import pytorch3d as p3d\n",
    "import torch\n",
    "from starter.utils import load_cow_mesh\n",
    "\n",
    "vertices, faces = load_cow_mesh('data/cow.obj')\n",
    "\n",
    "def color_interpolate(color1, color2, alpha):\n",
    "    return alpha * color2 + (1 - alpha) * color1\n",
    "\n",
    "z_min = vertices[:, 2].min()\n",
    "z_max = vertices[:, 2].max()\n",
    "\n",
    "color1 = torch.tensor([0.0, 0.0, 1.0])  # Blue color\n",
    "color2 = torch.tensor([1.0, 0.0, 0.0])  # Red color\n",
    "\n",
    "alphas = (vertices[:, 2] - z_min) / (z_max - z_min)\n",
    "\n",
    "textures = color_interpolate(color1[None, ...], color2[None, ...], alphas[..., None]).unsqueeze(0)\n",
    "vertices = vertices.unsqueeze(0)\n",
    "faces = faces.unsqueeze(0)\n",
    "\n",
    "cow_mesh = p3d.structures.Meshes(\n",
    "    verts=vertices,\n",
    "    faces=faces,\n",
    "    textures=p3d.renderer.TexturesVertex(textures)\n",
    ")\n",
    "\n",
    "camera360(cow_mesh, output_path=\"output/cow-retexture.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac5ce52",
   "metadata": {},
   "source": [
    "Result:\n",
    "\n",
    "- Color 1: Blue\n",
    "- Color 2: Red\n",
    "\n",
    "![](output/cow-retexture.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a55eb",
   "metadata": {},
   "source": [
    "# 4. Camera Transformations (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3eb426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x76144857b700>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch3d as p3d\n",
    "import numpy as np\n",
    "from starter.camera_transforms import render_textured_cow\n",
    "from starter.utils import get_mesh_renderer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "R_relative = [\n",
    "    [[1.0, 0.0, 0.0],\n",
    "     [0.0, 1.0, 0.0],\n",
    "     [0.0, 0.0, 1.0]],\n",
    "    [[0.0, 1.0, 0.0],\n",
    "     [-1.0, 0.0, 0.0],\n",
    "     [0.0, 0.0, 1.0]],\n",
    "    [[1.0, 0.0, 0.0],\n",
    "     [0.0, 1.0, 0.0],\n",
    "     [0.0, 0.0, 1.0]],\n",
    "    [[1.0, 0.0, 0.0],\n",
    "     [0.0, 1.0, 0.0],\n",
    "     [0.0, 0.0, 1.0]],\n",
    "    [[0.0, 0.0, 1.0],\n",
    "     [0.0, 1.0, 0.0],\n",
    "     [-1.0, 0.0, 0.0]],\n",
    "]\n",
    "T_relative = [\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 3.0],\n",
    "    [0.5, -0.5, 0.0],\n",
    "    [-3.0, 0.0, 3.0],\n",
    "]\n",
    "\n",
    "plt.ioff()\n",
    "for i in range(len(R_relative)):\n",
    "    image = render_textured_cow(cow_path=\"data/cow.obj\", R_relative=R_relative[i], T_relative=T_relative[i])\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.imsave(f\"output/cow_view_{i}.png\", image)\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa44e38d",
   "metadata": {},
   "source": [
    "R_relative and T_relative are another affine transformation pair that defines the camera's pose relative to the cow model.\n",
    "\n",
    "The formula to compute the new camera extrinsics is:\n",
    "\n",
    "R_relative and T_relative are another affine transformation pair that defines the camera's pose relative to the cow model.\n",
    "\n",
    "The formula to compute the new camera extrinsics is:\n",
    "\n",
    "$$\n",
    "R_{\\text{new}} = R_{\\text{relative}}\\,R_{\\text{cow}} \\\\\n",
    "T_{\\text{new}} = R_{\\text{relative}}\\,T_{\\text{cow}} + T_{\\text{relative}}\n",
    "$$\n",
    "\n",
    "The points will be transformed from world coordinates to camera coordinates using the new extrinsics.\n",
    "\n",
    "$$\n",
    "P_{\\text{camera}} = R_{\\text{relative}} \\cdot (R_{\\text{cow}} \\cdot P_{\\text{world}} + T_{\\text{cow}}) + T_{\\text{relative}}\n",
    "$$\n",
    "\n",
    "Results:\n",
    "\n",
    "![](output/cow_view_0.png) ![](output/cow_view_1.png) ![](output/cow_view_2.png) ![](output/cow_view_3.png) ![](output/cow_view_4.png) ![](output/cow_view_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ead104",
   "metadata": {},
   "source": [
    "# 5. Rendering Generic 3D Representations (45 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1e20860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from starter.utils import get_points_renderer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "def camera_point_360(point_cloud, img_size=256, num_frames=36, duration=1000, distance=3.0, elevation=15.0, output_path=None):\n",
    "    points_renderer = get_points_renderer(\n",
    "        image_size=img_size,\n",
    "        radius=0.01,\n",
    "    )\n",
    "\n",
    "    duration //= num_frames  # duration per frame in milliseconds\n",
    "    degrees = np.linspace(0, 360, num=num_frames).tolist()\n",
    "    my_images = []\n",
    "\n",
    "    for angle in tqdm(degrees):\n",
    "        R, T = p3d.renderer.cameras.look_at_view_transform(distance, elevation, angle)\n",
    "        cameras = p3d.renderer.FoVPerspectiveCameras(R=R, T=T, fov=60.0)\n",
    "        rend = points_renderer(point_cloud, cameras=cameras)\n",
    "        image = rend[0, ..., :3].numpy()  # (B, H, W, 4) -> (H, W, 3).\n",
    "        image = np.flipud(image)\n",
    "        my_images.append((image * 255).astype(np.uint8))\n",
    "\n",
    "    if output_path is not None:\n",
    "        imageio.mimsave(output_path, my_images, duration=duration, loop=0)\n",
    "        return None\n",
    "    else:\n",
    "        return my_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f093353",
   "metadata": {},
   "source": [
    "## 5.1 Rendering Point Clouds from RGB-D Images (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780ea98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:03<00:00, 15.76s/it]\n",
      "100%|██████████| 4/4 [00:59<00:00, 14.82s/it]\n",
      "100%|██████████| 4/4 [02:10<00:00, 32.53s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch3d as p3d\n",
    "from starter.render_generic import load_rgbd_data\n",
    "from starter.utils import unproject_depth_image\n",
    "\n",
    "data = load_rgbd_data()\n",
    "\n",
    "points1, rgba1 = unproject_depth_image(\n",
    "    torch.tensor(data['rgb1']),\n",
    "    torch.tensor(data['mask1']),\n",
    "    torch.tensor(data['depth1']),\n",
    "    data['cameras1'],\n",
    ")\n",
    "points2, rgba2 = unproject_depth_image(\n",
    "    torch.tensor(data['rgb2']),\n",
    "    torch.tensor(data['mask2']),\n",
    "    torch.tensor(data['depth2']),\n",
    "    data['cameras2'],\n",
    ")\n",
    "\n",
    "point_cloud1 = p3d.structures.Pointclouds(\n",
    "    points=[points1],\n",
    "    features=[rgba1[:, :3]],\n",
    ")\n",
    "point_cloud2 = p3d.structures.Pointclouds(\n",
    "    points=[points2],\n",
    "    features=[rgba2[:, :3]],\n",
    ")\n",
    "point_cloud_unified = p3d.structures.Pointclouds(\n",
    "    points=[torch.cat([points1, points2], dim=0)],\n",
    "    features=[torch.cat([rgba1[:, :3], rgba2[:, :3]], dim=0)],\n",
    ")\n",
    "\n",
    "camera_point_360(point_cloud1, distance=6.0, elevation=0, output_path=\"output/point_cloud1_360.gif\")\n",
    "camera_point_360(point_cloud2, distance=6.0, elevation=0, output_path=\"output/point_cloud2_360.gif\")\n",
    "camera_point_360(point_cloud_unified, distance=6.0, elevation=0, output_path=\"output/point_cloud_unified_360.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761250d6",
   "metadata": {},
   "source": [
    "![](output/point_cloud1_360.gif) ![](output/point_cloud2_360.gif) ![](output/point_cloud_unified_360.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b47f73",
   "metadata": {},
   "source": [
    "## 5.2 Parametric Functions (10 + 5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f71618",
   "metadata": {},
   "source": [
    "## 5.3 Implicit Surfaces (15 + 5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9755fe41",
   "metadata": {},
   "source": [
    "# 6. Do Something Fun (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1aaf9b",
   "metadata": {},
   "source": [
    "# (Extra Credit) 7. Sampling Points on Meshes (10 points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
